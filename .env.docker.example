# Example env file for docker-compose usage.
# Copy to `.env.docker` (gitignored) and run with:
#   docker compose --env-file .env.docker up --build
# or export COMPOSE_FILE overrides as needed.

# Core Discord (actual secrets should live only in developer private .env, not committed)
DISCORD_APP_ID=000000000000000000
DISCORD_PUBLIC_KEY=REPLACE_WITH_REAL_PUBLIC_KEY
DISCORD_GUILD_ID=000000000000000000
DISCORD_BOT_TOKEN=REDACTED_TOKEN_PLACEHOLDER
DISCORD_DEV_PUBLIC_KEY=REPLACE_WITH_DEV_PUBLIC_KEY

# Database (service hostname is 'db')
POSTGRES_USER=adventorator
POSTGRES_PASSWORD=adventorator
POSTGRES_DB=adventorator
DB_PORT=5432
APP_PORT=18000
DATABASE_URL=postgresql+asyncpg://adventorator:adventorator@db:5432/adventorator

# LLM (running outside the container on your host, typical for macOS):
# Use host.docker.internal so the app container can reach your host's Ollama.
LLM_API_PROVIDER=ollama                                 # ollama|openai
LLM_API_URL=http://host.docker.internal:11434           # Client normalizes to /api/chat
LLM_MODEL_NAME=llama3:8b                                # e.g., llama3:8b | gemma3:4b-it-q8_0 | dolphin-mistral:7b
LLM_API_KEY=ollama                                      # Not used by Ollama; arbitrary placeholder

# For OpenAI-compatible providers instead:
# LLM_API_PROVIDER=openai
# LLM_API_URL=https://api.openai.com                     # Base URL; client appends /v1
# LLM_API_KEY=replace-with-api-key
# LLM_MODEL_NAME=gpt-4o-mini

# Prompt and limits
LLM_DEFAULT_SYSTEM_PROMPT="You are a helpful assistant."
LLM_MAX_PROMPT_TOKENS=4096
LLM_MAX_RESPONSE_CHARS=4096

# Feature flags
FEATURES_LLM=true                                       # Master LLM toggle
FEATURES_LLM_VISIBLE=true                               # Show narration (false = shadow mode)
FEATURE_PLANNER_ENABLED=true
FEATURES_RULES=true
FEATURES_COMBAT=true
FEATURES_ACTION_VALIDATION=true
FEATURES_PREDICATE_GATE=true
FEATURES_MCP=false
FEATURES_ACTIVITY_LOG=true
FEATURES_PLANNING_TIERS=true
FEATURES_MAP=false
FEATURES_EVENTS=false
FEATURES_EXECUTOR=true
FEATURES_EXECUTOR_CONFIRM=true

ENV=dev

# Discord webhook override (Dev only): send follow-ups to the app itself
# DISCORD_WEBHOOK_URL_OVERRIDE=http://app:18000/dev-webhook

# Response timeout for Discord initial replies
RESPONSE_TIMEOUT_SECONDS=3

# Planner
PLANNER_TIMEOUT_SECONDS=20
PLANNER_MAX_LEVEL=1

# Retrieval (Phase 6)
RETRIEVAL__ENABLED=false
RETRIEVAL__PROVIDER=none                                # none|pgvector|qdrant
RETRIEVAL__TOP_K=4

# /ask Knowledge Base (Phase 3)
FEATURES_IMPROBABILITY_DRIVE=true
FEATURES_ASK=true
FEATURES_ASK_NLU_RULE_BASED=true
FEATURES_ASK_KB_LOOKUP=false
FEATURES_ASK_PLANNER_HANDOFF=false
FEATURES_ASK_NLU_DEBUG=false
ASK_KB__TIMEOUT_S=0.05
ASK_KB__MAX_CANDIDATES=5
ASK_KB__CACHE_TTL_S=60
ASK_KB__CACHE_MAX_SIZE=1024
ASK_KB__MAX_TERMS_PER_CALL=20

# Logging
LOGGING_ENABLED=true
LOGGING_LEVEL=DEBUG
LOGGING_CONSOLE=INFO
LOGGING_FILE=DEBUG
LOGGING_TO_CONSOLE=true
LOGGING_TO_FILE=true
LOGGING_FILE_PATH=logs/adventorator.jsonl
LOGGING_MAX_BYTES=5000000
LOGGING_BACKUP_COUNT=5

# Ops
METRICS_ENDPOINT_ENABLED=true
